{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./pic.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 83  55  54]\n",
      "  [ 83  55  54]\n",
      "  [ 83  55  54]\n",
      "  ...\n",
      "  [ 76  50  50]\n",
      "  [ 78  50  50]\n",
      "  [ 78  50  50]]\n",
      "\n",
      " [[ 56  35  33]\n",
      "  [ 56  35  33]\n",
      "  [ 56  35  33]\n",
      "  ...\n",
      "  [ 51  30  29]\n",
      "  [ 53  29  29]\n",
      "  [ 53  29  29]]\n",
      "\n",
      " [[ 23   4   1]\n",
      "  [ 23   4   1]\n",
      "  [ 23   4   1]\n",
      "  ...\n",
      "  [ 25   5   4]\n",
      "  [ 26   5   4]\n",
      "  [ 26   5   4]]]\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"original\",img)\n",
    "cv2.waitKey(3000)  # it takes the time for which images hould be on screen , if we give 0 or does not give anything then it will be on screen till the time till we dont click on cross\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img,(200,200)) # (width,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_img = cv2.imread(\"./pic.jpg\",0)  # it will generate graysacle image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_img = cv2.flip(bw_img,0)     # 0 -> rotate 90 , 1-> rotate 180 , -1 -> rotate 270\n",
    "cv2.imshow(\"bw_original\",bw_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"original\",img)\n",
    "k = cv2.waitKey()       \n",
    "if k == ord(\"s\"):       # if user press 's' then save it\n",
    "    cv2.imwrite(r\"C:\\Users\\tusha\\Desktop\\Computer vision\\output.jpg\",img)   # function for saving image\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.VideoCapture 000001FA48EFE5D0>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"./video.mp4\")\n",
    "print(cap)\n",
    "while True:\n",
    "    ret,frame = cap.read()  # cap gives two variables one is binary which we have stored in ret and another is image which we have stored in frame\n",
    "    frame = cv2.resize(frame,(700,250))\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)   # convert video to grayscale\n",
    "    cv2.imshow(\"frame\",gray)\n",
    "    k = cv2.waitKey(25)     # more value of waitkey will slow the frame speed (25 is normal playback)\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using webcam and saving video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # pass 0 to access webcam\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")    # it tells the video format\n",
    "output = cv2.VideoWriter(\"output.avi\",fourcc,20.0,(1000,700))   # it saves video (filename,format,fps,framesize)\n",
    "while True:\n",
    "    ret,frame = cap.read()  \n",
    "    frame = cv2.resize(frame,(1000,700))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    output.write(frame)\n",
    "    k = cv2.waitKey(25)    \n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = \"http://192.168.29.53:8080/video\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.open(camera)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output = cv2.VideoWriter(\"output_mobile.avi\",fourcc,20.0,(1000,700))\n",
    "while True:\n",
    "    ret,frame = cap.read()  \n",
    "    frame = cv2.resize(frame,(1000,700))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    output.write(frame)\n",
    "    k = cv2.waitKey(5)    \n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### capturing online videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pafy\n",
    "url = \"https://www.youtube.com/watch?v=wIAs97ynODo&list=PLaHodugB5x-Ddy_H951h0VHjOjfzZNCBh&index=7\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = pafy.new(url)\n",
    "data = data.getbest(preftype=\"mp4\")\n",
    "cap.open(data.url)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output = cv2.VideoWriter(\"output_online.avi\",fourcc,20.0,(1000,700))\n",
    "while True:\n",
    "    ret,frame = cap.read()  \n",
    "    frame = cv2.resize(frame,(1000,700))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    output.write(frame)\n",
    "    k = cv2.waitKey(5)    \n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Screen Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Downloading PyAutoGUI-0.9.54.tar.gz (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.2 kB 330.3 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.2 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.2 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.2 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 41.0/61.2 kB 178.6 kB/s eta 0:00:01\n",
      "     ------------------------------- ------ 51.2/61.2 kB 187.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.2/61.2 kB 171.7 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pymsgbox (from pyautogui)\n",
      "  Downloading PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pytweening>=1.0.4 (from pyautogui)\n",
      "  Downloading pytweening-1.0.7.tar.gz (168 kB)\n",
      "     ---------------------------------------- 0.0/168.2 kB ? eta -:--:--\n",
      "     ------- ------------------------------- 30.7/168.2 kB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------- ------------ 112.6/168.2 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 168.2/168.2 kB 1.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyscreeze>=0.1.21 (from pyautogui)\n",
      "  Downloading PyScreeze-0.1.30.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pygetwindow>=0.0.5 (from pyautogui)\n",
      "  Downloading PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mouseinfo (from pyautogui)\n",
      "  Downloading MouseInfo-0.1.3.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyrect (from pygetwindow>=0.0.5->pyautogui)\n",
      "  Downloading PyRect-0.2.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Pillow>=9.3.0 in c:\\users\\tusha\\anaconda3\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (9.4.0)\n",
      "Collecting pyperclip (from mouseinfo->pyautogui)\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pyautogui, pygetwindow, pyscreeze, pytweening, mouseinfo, pymsgbox, pyperclip, pyrect\n",
      "  Building wheel for pyautogui (pyproject.toml): started\n",
      "  Building wheel for pyautogui (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyautogui: filename=PyAutoGUI-0.9.54-py3-none-any.whl size=37596 sha256=5cd4568eab15cd70356f1ad120068d6180aacefbff49a2ab0127b90e76ce4395\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\95\\dc\\b1\\fe122b791e0db8bf439a0e6e1d2628e48f10bf430cae13521b\n",
      "  Building wheel for pygetwindow (setup.py): started\n",
      "  Building wheel for pygetwindow (setup.py): finished with status 'done'\n",
      "  Created wheel for pygetwindow: filename=PyGetWindow-0.0.9-py3-none-any.whl size=11079 sha256=76caf7185b2566fdf1533956615333645f3302478584d0829180b131d1b7741c\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\07\\75\\0b\\7ca0b598eb4c21d43ba4bcc78a0538dfcf803a5997da33bc19\n",
      "  Building wheel for pyscreeze (pyproject.toml): started\n",
      "  Building wheel for pyscreeze (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyscreeze: filename=PyScreeze-0.1.30-py3-none-any.whl size=14401 sha256=3dc26a95f75c363176a931610f5d28d26aff6cf819c8cda1e37cecff45f1e27f\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\df\\bc\\15\\d685ca085ca4b11e46e54cc3da4e501a98856c7fea8f604500\n",
      "  Building wheel for pytweening (setup.py): started\n",
      "  Building wheel for pytweening (setup.py): finished with status 'done'\n",
      "  Created wheel for pytweening: filename=pytweening-1.0.7-py3-none-any.whl size=6214 sha256=bc166f7a6ccbb37f94c99ce47176830ff1d4951629c5754caea21662e3c8d09c\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\b2\\9b\\02\\059beba389e7e31a635bd9e8d9b7299f4ec11caca1f237f56d\n",
      "  Building wheel for mouseinfo (setup.py): started\n",
      "  Building wheel for mouseinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for mouseinfo: filename=MouseInfo-0.1.3-py3-none-any.whl size=10906 sha256=e7b77dbed4606ae8f72147dd6c05f4cc6413549d528d86252cdea2a40422aa1b\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\20\\0b\\7f\\939ac9ff785b09951c706150537572c00123412f260a6024f3\n",
      "  Building wheel for pymsgbox (pyproject.toml): started\n",
      "  Building wheel for pymsgbox (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7417 sha256=41905765e0e2b0aa7515e7d0ece7a4c3dc5fb4ee17d8910d9963025addaa2720\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\85\\92\\63\\e126ee5f33d8f2ed04f96e43ef5df7270a2f331848752e8662\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=f549a1ac108fd0fc694538d504a3556fcfc3625c437428db5e2d56b71106577c\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\70\\bd\\ba\\8ae5c080c895c9360fe6e153acda2dee82527374467eae061b\n",
      "  Building wheel for pyrect (setup.py): started\n",
      "  Building wheel for pyrect (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrect: filename=PyRect-0.2.0-py2.py3-none-any.whl size=11205 sha256=a4d6ff12f86b6a2eea4684f2afc2f9997f7821f228cfbfa3f1d5547279486ac0\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\c4\\e9\\fc\\b7a666dd4f9a3168fb44d643079b41d36ddab52f470707e820\n",
      "Successfully built pyautogui pygetwindow pyscreeze pytweening mouseinfo pymsgbox pyperclip pyrect\n",
      "Installing collected packages: pytweening, pyrect, pyperclip, pymsgbox, pyscreeze, pygetwindow, mouseinfo, pyautogui\n",
      "Successfully installed mouseinfo-0.1.3 pyautogui-0.9.54 pygetwindow-0.0.9 pymsgbox-1.0.9 pyperclip-1.8.2 pyrect-0.2.0 pyscreeze-0.1.30 pytweening-1.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui as p\n",
    "import numpy as np\n",
    "\n",
    "rs = p.size()\n",
    "fn = input(\"Please enter any file name and Path\")\n",
    "forcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter(fn,fourcc,60.0,rs)\n",
    "\n",
    "cv2.namedWindow('Live_Recording',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Live_Recording',(600,400))\n",
    "\n",
    "while True:\n",
    "    img = p.screenshot()\n",
    "    f = np.array(img)\n",
    "    f = cv2.cvtColor(f,cv2.COLOR_BGR2RGB)\n",
    "    output.write(f)\n",
    "    cv2.imshow(\"Live_Recording\",f)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break video into multiple images and store in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "videocap = cv2.VideoCapture('video.mp4')\n",
    "ret,image = videocap.read()\n",
    "count = 0 \n",
    "while True:\n",
    "    if ret == True:\n",
    "        cv2.imwrite(r\"C:\\Users\\tusha\\Desktop\\Computer vision\\frames\\imgN%d.jpg\"%count,image)\n",
    "        videocap.set(cv2.CAP_PROP_POS_MSEC,(count**100))    # it helps in taking screenshots after set time\n",
    "        ret,image = videocap.read()\n",
    "        cv2.imshow(\"res\",image)\n",
    "        count+=1\n",
    "        if cv2.waitKey(1)== ord('q'):\n",
    "            break\n",
    "            cv2.destroyAllWindows()\n",
    "videocap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing function in opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros([512,512,3],np.uint8)*255 # black screen\n",
    "img = np.ones([512,512,3],np.uint8)*255  # white screen\n",
    "# img = cv2.imread('pic.jpg')\n",
    "img = cv2.line(img,(0,0),(200,200),(154,92,424),8)  # (img,staring,ending,color{BGR},thickness)\n",
    "img = cv2.arrowedLine(img,(0,125),(255,255),(255,0,0),10)\n",
    "img = cv2.rectangle(img,(325,225),(510,328),(255,255,0),-1) # if we take thickness as -1 then it will fill the shape\n",
    "img = cv2.circle(img,(425,525),25,(0,0,255),-1) # it will take radius instead of ending\n",
    "img = cv2.putText(img,'Tushar gupta',(20,500),cv2.FONT_ITALIC,2,(1,125,225),5,cv2.LINE_AA) #(img,text,starting,font,fontsize,color,thickness,linetype)\n",
    "cv2.imshow(\"res\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    frame = cv2.resize(frame,(1000,700))\n",
    "    text = 'Height : '+ str(cap.get(4)) + ' Width : ' + str(cap.get(3))\n",
    "    frame = cv2.putText(frame,text,(10,20),font,1,(0,0,0),1,cv2.LINE_AA)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(5)==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouse callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(event,x,y,flags,param):\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        cv2.circle(img,(x,y),100,(125,0,125),5)\n",
    "    if event == cv2.EVENT_RBUTTONDBLCLK:\n",
    "        cv2.rectangle(img,(x,y),(x+100,y+75),(125,125,125),2)\n",
    "\n",
    "cv2.namedWindow(winname='res')\n",
    "img = np.zeros([512,512,3],np.uint8)*255\n",
    "cv2.setMouseCallback(\"res\",draw)\n",
    "while True:\n",
    "    cv2.imshow(\"res\",img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to see cord and color on different click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_event(event,x,y,flag,param):\n",
    "    font  = cv2.FONT_HERSHEY_COMPLEX\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cord = \". \" + str(x) + \" , \" + str(y)\n",
    "        cv2.putText(img,cord,(x,y),font,1,(155,125,100),2)\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        b = img[y,x,0] # for blue channel is 0\n",
    "        g = img[y,x,1] # for green channel is 1\n",
    "        r = img[y,x,2] # for red channel is 2\n",
    "        color_bgr = \". \" + str(b) + \" , \" + str(g) +\" , \" + str(r)\n",
    "        cv2.putText(img,color_bgr,(x,y),font,1,(155,225,130),2)\n",
    "cv2.namedWindow(winname='res')\n",
    "img = cv2.imread('pic.jpg')\n",
    "cv2.setMouseCallback(\"res\",mouse_event)\n",
    "while True:\n",
    "    cv2.imshow(\"res\",img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLOR PICKER PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross(x):\n",
    "    pass\n",
    "\n",
    "img = np.zeros((300,512,3),np.uint8)\n",
    "cv2.namedWindow(\"Color picker\")\n",
    "\n",
    "s1 = \"0:OFF\\n1:ON\"\n",
    "cv2.createTrackbar(s1,\"Color picker\",0,1,cross)\n",
    "\n",
    "cv2.createTrackbar(\"R\",\"Color picker\",0,255,cross)\n",
    "cv2.createTrackbar(\"G\",\"Color picker\",0,255,cross)\n",
    "cv2.createTrackbar(\"B\",\"Color picker\",0,255,cross)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Color picker\",img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    s = cv2.getTrackbarPos(s1,\"Color picker\")\n",
    "    r = cv2.getTrackbarPos(\"R\",\"Color picker\")\n",
    "    g = cv2.getTrackbarPos(\"G\",\"Color picker\")\n",
    "    b = cv2.getTrackbarPos(\"B\",\"Color picker\")\n",
    "\n",
    "    if s==0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape =  (694, 540, 3)\n",
      "no. of pixels =  1124280\n",
      "datatype =  uint8\n",
      "image type =  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./pic.jpg')\n",
    "print('shape = ', img.shape)\n",
    "print(\"no. of pixels = \", img.size)\n",
    "print(\"datatype = \",img.dtype)\n",
    "print(\"image type = \",type(img))\n",
    "\n",
    "b,g,r = cv2.split(img)\n",
    "\n",
    "cv2.imshow(\"blue\",b)\n",
    "cv2.imshow(\"green\",g)\n",
    "cv2.imshow(\"red\",r)\n",
    "cv2.imshow(\"image\",img)\n",
    "\n",
    "mr1 = cv2.merge((r,g,b))\n",
    "cv2.imshow(\"rgb\",mr1)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"pic.jpg\")\n",
    "print(img.shape)\n",
    "# (115,43)                      (398 ,380)\n",
    "\n",
    "roi = img[45:380,115:400]      # (y1:y2,x1:x2)\n",
    "# dy = 335 , dx = 285\n",
    "img[24:380,401:500] = roi\n",
    "\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating image border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"pic.jpg\")\n",
    "brdr = cv2.copyMakeBorder(img,10,10,5,5,cv2.BORDER_CONSTANT,value = [225,0,125]) # (image,border-width,border-type,value)\n",
    "cv2.imshow(\"image\",brdr)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"pic.jpg\")\n",
    "img2 = cv2.imread(\"pic2.jpg\")\n",
    "img1 = cv2.resize(img1,(500,700))\n",
    "img2 = cv2.resize(img2,(500,700))\n",
    "# saturated blending\n",
    "result = cv2.add(img1, img2)\n",
    "# weighted blending \n",
    "result = cv2.addWeighted(img1,0.7,img2,0.3,0)   #(img1,weigt1,img2,weigt2,gamma)\n",
    "cv2.imshow(\"res\",result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img1 = cv2.imread(\"pic.jpg\")\n",
    "img2 = cv2.imread(\"pic2.jpg\")\n",
    "img1 = cv2.resize(img1,(500,700))\n",
    "img2 = cv2.resize(img2,(500,700))\n",
    "\n",
    "def blend(x):\n",
    "    pass\n",
    "\n",
    "img = np.zeros((400,400,3),np.uint8)\n",
    "cv2.namedWindow('win')\n",
    "cv2.createTrackbar('alpha','win',1,100,blend)\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch,'win',0,1,blend)\n",
    "\n",
    "while True:\n",
    "    s = cv2.getTrackbarPos(switch,'win')\n",
    "    a = cv2.getTrackbarPos('alpha','win')\n",
    "    n = float(a/100)\n",
    "    if s==0:\n",
    "        dst = img[:]\n",
    "    else:\n",
    "        dst = cv2.addWeighted(img1,1-n,img2,n,0)\n",
    "    cv2.imshow('dst',dst)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.zeros((250,500,3),np.uint8)\n",
    "img1 = cv2.rectangle(img1,(150,100),(200,250),(255,255,255),-1)\n",
    "img2 = np.zeros((250,500,3),np.uint8)\n",
    "img2 = cv2.rectangle(img2,(10,10),(170,190),(255,255,255),-1)\n",
    "cv2.imshow(\"img1\",img1)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "\n",
    "bitAnd = cv2.bitwise_and(img2,img1)\n",
    "cv2.imshow(\"bitAnd\",bitAnd)\n",
    "bitOr = cv2.bitwise_or(img2,img1)\n",
    "cv2.imshow(\"bitOr\",bitOr)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection using HSV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread('pic.jpg')\n",
    "while True:\n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    u_v  = np.array([100,100,150])\n",
    "    l_v  = np.array([0,0,100])\n",
    "    mask = cv2.inRange(hsv,l_v,u_v)\n",
    "    res = cv2.bitwise_and(frame,frame,mask=mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only color set on trackbar\n",
    "\n",
    "frame = cv2.imread('pic.jpg')\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Color Adjustments\")\n",
    "cv2.createTrackbar(\"Lower_H\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_S\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_V\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_H\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_S\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_V\", \"Color Adjustments\", 255, 255, nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"Lower_H\", \"Color Adjustments\")\n",
    "    l_s = cv2.getTrackbarPos(\"Lower_S\", \"Color Adjustments\")\n",
    "    l_v = cv2.getTrackbarPos(\"Lower_V\", \"Color Adjustments\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"Upper_H\", \"Color Adjustments\")\n",
    "    u_s = cv2.getTrackbarPos(\"Upper_S\", \"Color Adjustments\")\n",
    "    u_v = cv2.getTrackbarPos(\"Upper_V\", \"Color Adjustments\")\n",
    "    \n",
    "    lower_bound = np.array([l_h, l_s, l_v])\n",
    "    upper_bound = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting color using webcan and trackbar\n",
    "cap = cv2.VideoCapture(0)\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Color Adjustments\")\n",
    "cv2.createTrackbar(\"Lower_H\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_S\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_V\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_H\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_S\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_V\", \"Color Adjustments\", 255, 255, nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    frame = cv2.resize(frame,(400,400))\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"Lower_H\", \"Color Adjustments\")\n",
    "    l_s = cv2.getTrackbarPos(\"Lower_S\", \"Color Adjustments\")\n",
    "    l_v = cv2.getTrackbarPos(\"Lower_V\", \"Color Adjustments\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"Upper_H\", \"Color Adjustments\")\n",
    "    u_s = cv2.getTrackbarPos(\"Upper_S\", \"Color Adjustments\")\n",
    "    u_v = cv2.getTrackbarPos(\"Upper_V\", \"Color Adjustments\")\n",
    "    \n",
    "    lower_bound = np.array([l_h, l_s, l_v])\n",
    "    upper_bound = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('pic.jpg')\n",
    "# (img,start,end,function)\n",
    "_,th1 = cv2.threshold(img,100,255,cv2.THRESH_BINARY) # pixels having value less than 100 will be converted to 0 and rest converted to 255\n",
    "_,th2 = cv2.threshold(img,100,255,cv2.THRESH_BINARY_INV) # inverse of above case\n",
    "_,th3 = cv2.threshold(img,100,255,cv2.THRESH_TRUNC) # it will spread the start value and the value below start value remain as it is\n",
    "_,th4 = cv2.threshold(img,100,255,cv2.THRESH_TOZERO) # same for value above start value and the value below start value to 0\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.imshow('thresh binary',th1)\n",
    "# cv2.imshow('thresh binary inverse',th2)\n",
    "# cv2.imshow('thresh truncate',th3)\n",
    "cv2.imshow('thresh tozero',th4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaptive thresholding decides how thresholding value is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (img,pixel thresh,max pixel thresh,method,function,no. of pixels,contact_mean)\n",
    "img = cv2.imread('pic.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "th1 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "cv2.imshow('gray',gray)\n",
    "cv2.imshow('mean adaptive',th1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roi using thresholding and bitwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/hero1.jpg')\n",
    "img2 = cv2.imread('Data/strom_breaker.JPG')\n",
    "img1 = cv2.resize(img1,(1024,650))\n",
    "img2 = cv2.resize(img2,(600,650))\n",
    "\n",
    "r,c,ch = img2.shape   # row ,col, channels\n",
    "roi = img1[0:r,0:c]\n",
    "\n",
    "img_gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)  # creating mask for img2\n",
    "\n",
    "_,mask = cv2.threshold(img_gray,50,255,cv2.THRESH_BINARY) # create mask using threshold\n",
    "\n",
    "mask_inv = cv2.bitwise_not(mask)    # remove background\n",
    "\n",
    "img1_bg = cv2.bitwise_and(roi,roi,mask=mask_inv)    # put background on roi\n",
    "\n",
    "img2_fg = cv2.bitwise_and(img2,img2,mask=mask) # taking masked region from original image\n",
    "\n",
    "res = cv2.add(img1_bg,img2_fg)   # put img in ROI \n",
    "\n",
    "final = img1\n",
    "\n",
    "final[0:r,0:c] = res\n",
    "\n",
    "cv2.imshow('final',final)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
