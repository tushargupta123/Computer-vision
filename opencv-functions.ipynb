{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./pic.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 83  55  54]\n",
      "  [ 83  55  54]\n",
      "  [ 83  55  54]\n",
      "  ...\n",
      "  [ 76  50  50]\n",
      "  [ 78  50  50]\n",
      "  [ 78  50  50]]\n",
      "\n",
      " [[ 56  35  33]\n",
      "  [ 56  35  33]\n",
      "  [ 56  35  33]\n",
      "  ...\n",
      "  [ 51  30  29]\n",
      "  [ 53  29  29]\n",
      "  [ 53  29  29]]\n",
      "\n",
      " [[ 23   4   1]\n",
      "  [ 23   4   1]\n",
      "  [ 23   4   1]\n",
      "  ...\n",
      "  [ 25   5   4]\n",
      "  [ 26   5   4]\n",
      "  [ 26   5   4]]]\n"
     ]
    }
   ],
   "source": [
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"original\",img)\n",
    "cv2.waitKey(3000)  # it takes the time for which images hould be on screen , if we give 0 or does not give anything then it will be on screen till the time till we dont click on cross\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.resize(img,(200,200)) # (width,height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_img = cv2.imread(\"./pic.jpg\",0)  # it will generate graysacle image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_img = cv2.flip(bw_img,0)     # 0 -> rotate 90 , 1-> rotate 180 , -1 -> rotate 270\n",
    "cv2.imshow(\"bw_original\",bw_img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"original\",img)\n",
    "k = cv2.waitKey()       \n",
    "if k == ord(\"s\"):       # if user press 's' then save it\n",
    "    cv2.imwrite(r\"C:\\Users\\tusha\\Desktop\\Computer vision\\output.jpg\",img)   # function for saving image\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< cv2.VideoCapture 000001FA48EFE5D0>\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"./video.mp4\")\n",
    "print(cap)\n",
    "while True:\n",
    "    ret,frame = cap.read()  # cap gives two variables one is binary which we have stored in ret and another is image which we have stored in frame\n",
    "    frame = cv2.resize(frame,(700,250))\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)   # convert video to grayscale\n",
    "    cv2.imshow(\"frame\",gray)\n",
    "    k = cv2.waitKey(25)     # more value of waitkey will slow the frame speed (25 is normal playback)\n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using webcam and saving video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)  # pass 0 to access webcam\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")    # it tells the video format\n",
    "output = cv2.VideoWriter(\"output.avi\",fourcc,20.0,(1000,700))   # it saves video (filename,format,fps,framesize)\n",
    "while True:\n",
    "    ret,frame = cap.read()  \n",
    "    frame = cv2.resize(frame,(1000,700))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    output.write(frame)\n",
    "    k = cv2.waitKey(25)    \n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = \"http://192.168.29.53:8080/video\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.open(camera)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output = cv2.VideoWriter(\"output_mobile.avi\",fourcc,20.0,(1000,700))\n",
    "while True:\n",
    "    ret,frame = cap.read()  \n",
    "    frame = cv2.resize(frame,(1000,700))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    output.write(frame)\n",
    "    k = cv2.waitKey(5)    \n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### capturing online videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pafy\n",
    "url = \"https://www.youtube.com/watch?v=wIAs97ynODo&list=PLaHodugB5x-Ddy_H951h0VHjOjfzZNCBh&index=7\"\n",
    "cap = cv2.VideoCapture(0)\n",
    "data = pafy.new(url)\n",
    "data = data.getbest(preftype=\"mp4\")\n",
    "cap.open(data.url)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "output = cv2.VideoWriter(\"output_online.avi\",fourcc,20.0,(1000,700))\n",
    "while True:\n",
    "    ret,frame = cap.read()  \n",
    "    frame = cv2.resize(frame,(1000,700))\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    output.write(frame)\n",
    "    k = cv2.waitKey(5)    \n",
    "    if k == ord(\"q\"):\n",
    "        break\n",
    "cap.release()\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Screen Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Downloading PyAutoGUI-0.9.54.tar.gz (61 kB)\n",
      "     ---------------------------------------- 0.0/61.2 kB ? eta -:--:--\n",
      "     ------------ ------------------------- 20.5/61.2 kB 330.3 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.2 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.2 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------- ------------------ 30.7/61.2 kB 435.7 kB/s eta 0:00:01\n",
      "     ------------------------- ------------ 41.0/61.2 kB 178.6 kB/s eta 0:00:01\n",
      "     ------------------------------- ------ 51.2/61.2 kB 187.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 61.2/61.2 kB 171.7 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pymsgbox (from pyautogui)\n",
      "  Downloading PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pytweening>=1.0.4 (from pyautogui)\n",
      "  Downloading pytweening-1.0.7.tar.gz (168 kB)\n",
      "     ---------------------------------------- 0.0/168.2 kB ? eta -:--:--\n",
      "     ------- ------------------------------- 30.7/168.2 kB 1.4 MB/s eta 0:00:01\n",
      "     ------------------------- ------------ 112.6/168.2 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 168.2/168.2 kB 1.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyscreeze>=0.1.21 (from pyautogui)\n",
      "  Downloading PyScreeze-0.1.30.tar.gz (27 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pygetwindow>=0.0.5 (from pyautogui)\n",
      "  Downloading PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mouseinfo (from pyautogui)\n",
      "  Downloading MouseInfo-0.1.3.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pyrect (from pygetwindow>=0.0.5->pyautogui)\n",
      "  Downloading PyRect-0.2.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: Pillow>=9.3.0 in c:\\users\\tusha\\anaconda3\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (9.4.0)\n",
      "Collecting pyperclip (from mouseinfo->pyautogui)\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: pyautogui, pygetwindow, pyscreeze, pytweening, mouseinfo, pymsgbox, pyperclip, pyrect\n",
      "  Building wheel for pyautogui (pyproject.toml): started\n",
      "  Building wheel for pyautogui (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyautogui: filename=PyAutoGUI-0.9.54-py3-none-any.whl size=37596 sha256=5cd4568eab15cd70356f1ad120068d6180aacefbff49a2ab0127b90e76ce4395\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\95\\dc\\b1\\fe122b791e0db8bf439a0e6e1d2628e48f10bf430cae13521b\n",
      "  Building wheel for pygetwindow (setup.py): started\n",
      "  Building wheel for pygetwindow (setup.py): finished with status 'done'\n",
      "  Created wheel for pygetwindow: filename=PyGetWindow-0.0.9-py3-none-any.whl size=11079 sha256=76caf7185b2566fdf1533956615333645f3302478584d0829180b131d1b7741c\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\07\\75\\0b\\7ca0b598eb4c21d43ba4bcc78a0538dfcf803a5997da33bc19\n",
      "  Building wheel for pyscreeze (pyproject.toml): started\n",
      "  Building wheel for pyscreeze (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pyscreeze: filename=PyScreeze-0.1.30-py3-none-any.whl size=14401 sha256=3dc26a95f75c363176a931610f5d28d26aff6cf819c8cda1e37cecff45f1e27f\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\df\\bc\\15\\d685ca085ca4b11e46e54cc3da4e501a98856c7fea8f604500\n",
      "  Building wheel for pytweening (setup.py): started\n",
      "  Building wheel for pytweening (setup.py): finished with status 'done'\n",
      "  Created wheel for pytweening: filename=pytweening-1.0.7-py3-none-any.whl size=6214 sha256=bc166f7a6ccbb37f94c99ce47176830ff1d4951629c5754caea21662e3c8d09c\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\b2\\9b\\02\\059beba389e7e31a635bd9e8d9b7299f4ec11caca1f237f56d\n",
      "  Building wheel for mouseinfo (setup.py): started\n",
      "  Building wheel for mouseinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for mouseinfo: filename=MouseInfo-0.1.3-py3-none-any.whl size=10906 sha256=e7b77dbed4606ae8f72147dd6c05f4cc6413549d528d86252cdea2a40422aa1b\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\20\\0b\\7f\\939ac9ff785b09951c706150537572c00123412f260a6024f3\n",
      "  Building wheel for pymsgbox (pyproject.toml): started\n",
      "  Building wheel for pymsgbox (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7417 sha256=41905765e0e2b0aa7515e7d0ece7a4c3dc5fb4ee17d8910d9963025addaa2720\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\85\\92\\63\\e126ee5f33d8f2ed04f96e43ef5df7270a2f331848752e8662\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=f549a1ac108fd0fc694538d504a3556fcfc3625c437428db5e2d56b71106577c\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\70\\bd\\ba\\8ae5c080c895c9360fe6e153acda2dee82527374467eae061b\n",
      "  Building wheel for pyrect (setup.py): started\n",
      "  Building wheel for pyrect (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrect: filename=PyRect-0.2.0-py2.py3-none-any.whl size=11205 sha256=a4d6ff12f86b6a2eea4684f2afc2f9997f7821f228cfbfa3f1d5547279486ac0\n",
      "  Stored in directory: c:\\users\\tusha\\appdata\\local\\pip\\cache\\wheels\\c4\\e9\\fc\\b7a666dd4f9a3168fb44d643079b41d36ddab52f470707e820\n",
      "Successfully built pyautogui pygetwindow pyscreeze pytweening mouseinfo pymsgbox pyperclip pyrect\n",
      "Installing collected packages: pytweening, pyrect, pyperclip, pymsgbox, pyscreeze, pygetwindow, mouseinfo, pyautogui\n",
      "Successfully installed mouseinfo-0.1.3 pyautogui-0.9.54 pygetwindow-0.0.9 pymsgbox-1.0.9 pyperclip-1.8.2 pyrect-0.2.0 pyscreeze-0.1.30 pytweening-1.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui as p\n",
    "import numpy as np\n",
    "\n",
    "rs = p.size()\n",
    "fn = input(\"Please enter any file name and Path\")\n",
    "forcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output = cv2.VideoWriter(fn,fourcc,60.0,rs)\n",
    "\n",
    "cv2.namedWindow('Live_Recording',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Live_Recording',(600,400))\n",
    "\n",
    "while True:\n",
    "    img = p.screenshot()\n",
    "    f = np.array(img)\n",
    "    f = cv2.cvtColor(f,cv2.COLOR_BGR2RGB)\n",
    "    output.write(f)\n",
    "    cv2.imshow(\"Live_Recording\",f)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "output.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Break video into multiple images and store in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "videocap = cv2.VideoCapture('video.mp4')\n",
    "ret,image = videocap.read()\n",
    "count = 0 \n",
    "while True:\n",
    "    if ret == True:\n",
    "        cv2.imwrite(r\"C:\\Users\\tusha\\Desktop\\Computer vision\\frames\\imgN%d.jpg\"%count,image)\n",
    "        videocap.set(cv2.CAP_PROP_POS_MSEC,(count**100))    # it helps in taking screenshots after set time\n",
    "        ret,image = videocap.read()\n",
    "        cv2.imshow(\"res\",image)\n",
    "        count+=1\n",
    "        if cv2.waitKey(1)== ord('q'):\n",
    "            break\n",
    "            cv2.destroyAllWindows()\n",
    "videocap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing function in opencv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.zeros([512,512,3],np.uint8)*255 # black screen\n",
    "img = np.ones([512,512,3],np.uint8)*255  # white screen\n",
    "# img = cv2.imread('pic.jpg')\n",
    "img = cv2.line(img,(0,0),(200,200),(154,92,424),8)  # (img,staring,ending,color{BGR},thickness)\n",
    "img = cv2.arrowedLine(img,(0,125),(255,255),(255,0,0),10)\n",
    "img = cv2.rectangle(img,(325,225),(510,328),(255,255,0),-1) # if we take thickness as -1 then it will fill the shape\n",
    "img = cv2.circle(img,(425,525),25,(0,0,255),-1) # it will take radius instead of ending\n",
    "img = cv2.putText(img,'Tushar gupta',(20,500),cv2.FONT_ITALIC,2,(1,125,225),5,cv2.LINE_AA) #(img,text,starting,font,fontsize,color,thickness,linetype)\n",
    "cv2.imshow(\"res\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(cap.isOpened()):\n",
    "    ret,frame = cap.read()\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "    frame = cv2.resize(frame,(1000,700))\n",
    "    text = 'Height : '+ str(cap.get(4)) + ' Width : ' + str(cap.get(3))\n",
    "    frame = cv2.putText(frame,text,(10,20),font,1,(0,0,0),1,cv2.LINE_AA)\n",
    "    cv2.imshow('frame',frame)\n",
    "    if cv2.waitKey(5)==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mouse callback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(event,x,y,flags,param):\n",
    "    if event == cv2.EVENT_LBUTTONDBLCLK:\n",
    "        cv2.circle(img,(x,y),100,(125,0,125),5)\n",
    "    if event == cv2.EVENT_RBUTTONDBLCLK:\n",
    "        cv2.rectangle(img,(x,y),(x+100,y+75),(125,125,125),2)\n",
    "\n",
    "cv2.namedWindow(winname='res')\n",
    "img = np.zeros([512,512,3],np.uint8)*255\n",
    "cv2.setMouseCallback(\"res\",draw)\n",
    "while True:\n",
    "    cv2.imshow(\"res\",img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to see cord and color on different click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mouse_event(event,x,y,flag,param):\n",
    "    font  = cv2.FONT_HERSHEY_COMPLEX\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        cord = \". \" + str(x) + \" , \" + str(y)\n",
    "        cv2.putText(img,cord,(x,y),font,1,(155,125,100),2)\n",
    "    if event == cv2.EVENT_RBUTTONDOWN:\n",
    "        b = img[y,x,0] # for blue channel is 0\n",
    "        g = img[y,x,1] # for green channel is 1\n",
    "        r = img[y,x,2] # for red channel is 2\n",
    "        color_bgr = \". \" + str(b) + \" , \" + str(g) +\" , \" + str(r)\n",
    "        cv2.putText(img,color_bgr,(x,y),font,1,(155,225,130),2)\n",
    "cv2.namedWindow(winname='res')\n",
    "img = cv2.imread('pic.jpg')\n",
    "cv2.setMouseCallback(\"res\",mouse_event)\n",
    "while True:\n",
    "    cv2.imshow(\"res\",img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLOR PICKER PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross(x):\n",
    "    pass\n",
    "\n",
    "img = np.zeros((300,512,3),np.uint8)\n",
    "cv2.namedWindow(\"Color picker\")\n",
    "\n",
    "s1 = \"0:OFF\\n1:ON\"\n",
    "cv2.createTrackbar(s1,\"Color picker\",0,1,cross)\n",
    "\n",
    "cv2.createTrackbar(\"R\",\"Color picker\",0,255,cross)\n",
    "cv2.createTrackbar(\"G\",\"Color picker\",0,255,cross)\n",
    "cv2.createTrackbar(\"B\",\"Color picker\",0,255,cross)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"Color picker\",img)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "    s = cv2.getTrackbarPos(s1,\"Color picker\")\n",
    "    r = cv2.getTrackbarPos(\"R\",\"Color picker\")\n",
    "    g = cv2.getTrackbarPos(\"G\",\"Color picker\")\n",
    "    b = cv2.getTrackbarPos(\"B\",\"Color picker\")\n",
    "\n",
    "    if s==0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b,g,r]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape =  (694, 540, 3)\n",
      "no. of pixels =  1124280\n",
      "datatype =  uint8\n",
      "image type =  <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('./pic.jpg')\n",
    "print('shape = ', img.shape)\n",
    "print(\"no. of pixels = \", img.size)\n",
    "print(\"datatype = \",img.dtype)\n",
    "print(\"image type = \",type(img))\n",
    "\n",
    "b,g,r = cv2.split(img)\n",
    "\n",
    "cv2.imshow(\"blue\",b)\n",
    "cv2.imshow(\"green\",g)\n",
    "cv2.imshow(\"red\",r)\n",
    "cv2.imshow(\"image\",img)\n",
    "\n",
    "mr1 = cv2.merge((r,g,b))\n",
    "cv2.imshow(\"rgb\",mr1)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"pic.jpg\")\n",
    "print(img.shape)\n",
    "# (115,43)                      (398 ,380)\n",
    "\n",
    "roi = img[45:380,115:400]      # (y1:y2,x1:x2)\n",
    "# dy = 335 , dx = 285\n",
    "img[24:380,401:500] = roi\n",
    "\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating image border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"pic.jpg\")\n",
    "brdr = cv2.copyMakeBorder(img,10,10,5,5,cv2.BORDER_CONSTANT,value = [225,0,125]) # (image,border-width,border-type,value)\n",
    "cv2.imshow(\"image\",brdr)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"pic.jpg\")\n",
    "img2 = cv2.imread(\"pic2.jpg\")\n",
    "img1 = cv2.resize(img1,(500,700))\n",
    "img2 = cv2.resize(img2,(500,700))\n",
    "# saturated blending\n",
    "result = cv2.add(img1, img2)\n",
    "# weighted blending \n",
    "result = cv2.addWeighted(img1,0.7,img2,0.3,0)   #(img1,weigt1,img2,weigt2,gamma)\n",
    "cv2.imshow(\"res\",result)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'win' in function 'cvGetTrackbarPos'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tusha\\Desktop\\Computer vision\\opencv-functions.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusha/Desktop/Computer%20vision/opencv-functions.ipynb#X56sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m cv2\u001b[39m.\u001b[39mcreateTrackbar(switch,\u001b[39m'\u001b[39m\u001b[39mwin\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m,blend)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusha/Desktop/Computer%20vision/opencv-functions.ipynb#X56sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tusha/Desktop/Computer%20vision/opencv-functions.ipynb#X56sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     s \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mgetTrackbarPos(switch,\u001b[39m'\u001b[39;49m\u001b[39mwin\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusha/Desktop/Computer%20vision/opencv-functions.ipynb#X56sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     a \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mgetTrackbarPos(\u001b[39m'\u001b[39m\u001b[39malpha\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mwin\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tusha/Desktop/Computer%20vision/opencv-functions.ipynb#X56sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(a\u001b[39m/\u001b[39m\u001b[39m100\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window_w32.cpp:2561: error: (-27:Null pointer) NULL window: 'win' in function 'cvGetTrackbarPos'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "img1 = cv2.imread(\"pic.jpg\")\n",
    "img2 = cv2.imread(\"pic2.jpg\")\n",
    "img1 = cv2.resize(img1,(500,700))\n",
    "img2 = cv2.resize(img2,(500,700))\n",
    "\n",
    "def blend(x):\n",
    "    pass\n",
    "\n",
    "img = np.zeros((400,400,3),np.uint8)\n",
    "cv2.namedWindow('win')\n",
    "cv2.createTrackbar('alpha','win',1,100,blend)\n",
    "switch = '0 : OFF \\n1 : ON'\n",
    "cv2.createTrackbar(switch,'win',0,1,blend)\n",
    "\n",
    "while True:\n",
    "    s = cv2.getTrackbarPos(switch,'win')\n",
    "    a = cv2.getTrackbarPos('alpha','win')\n",
    "    n = float(a/100)\n",
    "    if s==0:\n",
    "        dst = img[:]\n",
    "    else:\n",
    "        dst = cv2.addWeighted(img1,1-n,img2,n,0)\n",
    "    cv2.imshow('dst',dst)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bitwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = np.zeros((250,500,3),np.uint8)\n",
    "img1 = cv2.rectangle(img1,(150,100),(200,250),(255,255,255),-1)\n",
    "img2 = np.zeros((250,500,3),np.uint8)\n",
    "img2 = cv2.rectangle(img2,(10,10),(170,190),(255,255,255),-1)\n",
    "cv2.imshow(\"img1\",img1)\n",
    "cv2.imshow(\"img2\",img2)\n",
    "\n",
    "bitAnd = cv2.bitwise_and(img2,img1)\n",
    "cv2.imshow(\"bitAnd\",bitAnd)\n",
    "bitOr = cv2.bitwise_or(img2,img1)\n",
    "cv2.imshow(\"bitOr\",bitOr)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection using HSV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = cv2.imread('pic.jpg')\n",
    "while True:\n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "    u_v  = np.array([100,100,150])\n",
    "    l_v  = np.array([0,0,100])\n",
    "    mask = cv2.inRange(hsv,l_v,u_v)\n",
    "    res = cv2.bitwise_and(frame,frame,mask=mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only color set on trackbar\n",
    "\n",
    "frame = cv2.imread('pic.jpg')\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Color Adjustments\")\n",
    "cv2.createTrackbar(\"Lower_H\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_S\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_V\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_H\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_S\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_V\", \"Color Adjustments\", 255, 255, nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"Lower_H\", \"Color Adjustments\")\n",
    "    l_s = cv2.getTrackbarPos(\"Lower_S\", \"Color Adjustments\")\n",
    "    l_v = cv2.getTrackbarPos(\"Lower_V\", \"Color Adjustments\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"Upper_H\", \"Color Adjustments\")\n",
    "    u_s = cv2.getTrackbarPos(\"Upper_S\", \"Color Adjustments\")\n",
    "    u_v = cv2.getTrackbarPos(\"Upper_V\", \"Color Adjustments\")\n",
    "    \n",
    "    lower_bound = np.array([l_h, l_s, l_v])\n",
    "    upper_bound = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting color using webcan and trackbar\n",
    "cap = cv2.VideoCapture(0)\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Color Adjustments\")\n",
    "cv2.createTrackbar(\"Lower_H\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_S\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_V\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_H\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_S\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_V\", \"Color Adjustments\", 255, 255, nothing)\n",
    "\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    frame = cv2.resize(frame,(400,400))\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    l_h = cv2.getTrackbarPos(\"Lower_H\", \"Color Adjustments\")\n",
    "    l_s = cv2.getTrackbarPos(\"Lower_S\", \"Color Adjustments\")\n",
    "    l_v = cv2.getTrackbarPos(\"Lower_V\", \"Color Adjustments\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"Upper_H\", \"Color Adjustments\")\n",
    "    u_s = cv2.getTrackbarPos(\"Upper_S\", \"Color Adjustments\")\n",
    "    u_v = cv2.getTrackbarPos(\"Upper_V\", \"Color Adjustments\")\n",
    "    \n",
    "    lower_bound = np.array([l_h, l_s, l_v])\n",
    "    upper_bound = np.array([u_h, u_s, u_v])\n",
    "    \n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('pic.jpg')\n",
    "# (img,start,end,function)\n",
    "_,th1 = cv2.threshold(img,100,255,cv2.THRESH_BINARY) # pixels having value less than 100 will be converted to 0 and rest converted to 255\n",
    "_,th2 = cv2.threshold(img,100,255,cv2.THRESH_BINARY_INV) # inverse of above case\n",
    "_,th3 = cv2.threshold(img,100,255,cv2.THRESH_TRUNC) # it will spread the start value and the value below start value remain as it is\n",
    "_,th4 = cv2.threshold(img,100,255,cv2.THRESH_TOZERO) # same for value above start value and the value below start value to 0\n",
    "# cv2.imshow('img',img)\n",
    "# cv2.imshow('thresh binary',th1)\n",
    "# cv2.imshow('thresh binary inverse',th2)\n",
    "# cv2.imshow('thresh truncate',th3)\n",
    "cv2.imshow('thresh tozero',th4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaptive thresholding decides how thresholding value is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (img,pixel thresh,max pixel thresh,method,function,no. of pixels,contact_mean)\n",
    "img = cv2.imread('pic.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "th1 = cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,11,2)\n",
    "cv2.imshow('gray',gray)\n",
    "cv2.imshow('mean adaptive',th1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roi using thresholding and bitwise operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Data/hero1.jpg')\n",
    "img2 = cv2.imread('Data/strom_breaker.JPG')\n",
    "img1 = cv2.resize(img1,(1024,650))\n",
    "img2 = cv2.resize(img2,(600,650))\n",
    "\n",
    "r,c,ch = img2.shape   # row ,col, channels\n",
    "roi = img1[0:r,0:c]\n",
    "\n",
    "img_gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)  # creating mask for img2\n",
    "\n",
    "_,mask = cv2.threshold(img_gray,50,255,cv2.THRESH_BINARY) # create mask using threshold\n",
    "\n",
    "mask_inv = cv2.bitwise_not(mask)    # remove background\n",
    "\n",
    "img1_bg = cv2.bitwise_and(roi,roi,mask=mask_inv)    # put background on roi\n",
    "\n",
    "img2_fg = cv2.bitwise_and(img2,img2,mask=mask) # taking masked region from original image\n",
    "\n",
    "res = cv2.add(img1_bg,img2_fg)   # put img in ROI \n",
    "\n",
    "final = img1\n",
    "\n",
    "final[0:r,0:c] = res\n",
    "\n",
    "cv2.imshow('final',final)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphological Transformations\n",
    "These are the operations that are based on image shape . it is performed on image shape. \n",
    "1. erosion - it erodes the boundaries of the foreground object\n",
    "kernal slides through all the image and all the pixel from the orginal image consider 1 only if kernal's pixel is 1\n",
    "2. Dilation - It is just opposite of erosion.Here, a pixel element is ‘1’ if atleast one pixel under the kernel is ‘1’.So it inc. the white region in the image or size of foreground object in.Normally, in cases like noise removal, erosion is followed by dilation. Because, erosion removes white noises, but it also shrinks our object.\n",
    "3. Opening - It is erosion followed by dilation\n",
    "4. Closing - It is opposite of opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Data/col_balls.jpg',0)    # we will work on binary , i.e. , grayscale images\n",
    "_,mask = cv2.threshold(img,230,255,cv2.THRESH_BINARY_INV)   # we have to keep background black and foreground white so we are using inv\n",
    "kernal = np.ones((5,5),np.uint8)  # 5X5 kernal with full ones.\n",
    "e = cv2.erode(mask,kernal) # we will now float the kernal on mask and make the edges of object more sharp with erosion\n",
    "\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"mask\",mask)\n",
    "cv2.imshow(\"erosion\",e)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "erosion sharpens boundary very well but it increases the distortion (age beech mei khi black tha to usko aur black kr dia jbki usse white hona chahiye tha) between the object \n",
    "so thats why we use dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((4,4),np.uint8)\n",
    "d = cv2.dilate(mask,kernel)\n",
    "cv2.imshow(\"dilation\",d)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Data/col_balls.jpg',0)    \n",
    "_,mask = cv2.threshold(img,230,255,cv2.THRESH_BINARY_INV)   \n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "o = cv2.morphologyEx(mask,cv2.MORPH_OPEN,kernel) \n",
    "\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"mask\",mask)\n",
    "cv2.imshow(\"opening\",o)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Data/col_balls.jpg',0)    \n",
    "_,mask = cv2.threshold(img,230,255,cv2.THRESH_BINARY_INV)   \n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "c = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,kernel) \n",
    "\n",
    "cv2.imshow(\"img\",img)\n",
    "cv2.imshow(\"mask\",mask)\n",
    "cv2.imshow(\"clsing\",c)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img  = cv2.imread('Data/noisy.jpg')\n",
    "cv2.imshow(\"original\",img)\n",
    "\n",
    "# filter 1\n",
    "# this filter work like ,each output pixel is the mean of its kernal neighbor\n",
    "# it is aka homogeneous filter int his all pixel contribute with equal weight\n",
    "# kernal is a small shape or matrix which we can apply on image\n",
    "# in this filter kernal is [(1/kernal(h,w))*kernal]\n",
    "kernel = np.ones((5,5),np.float32)/25\n",
    "h_filter = cv2.filter2D(img,-1,kernel)  # -1 is desired depth\n",
    "cv2.imshow(\"homogeneous\",h_filter)\n",
    "\n",
    "# filter 2\n",
    "# blur method or averaging\n",
    "# takes the average of all the pixels under kernel area and\n",
    "# replaces the central element with this average\n",
    "blur = cv2.blur(img,(8,8))  # here we pass kernel size\n",
    "cv2.imshow('blur',blur)\n",
    "\n",
    "# filter 3\n",
    "# gaussian filter\n",
    "# here it using different weight kernel , in row as well as column\n",
    "# mean side values are small then centre . It manages distance b/w value of pixel\n",
    "\n",
    "gau = cv2.GaussianBlur(img,(5,5),0)  # here 0 is a sigma-x value\n",
    "cv2.imshow(\"gaussian blur\",gau)\n",
    "\n",
    "# filter 4\n",
    "# median filter \n",
    "# computes the median of all the pixels under the kernel window and the central\n",
    "# pixel is replaced with this median value\n",
    "# This is highly effective in removing salt-and-pepper noise (where there are white dots on black color)\n",
    "# here kernel size must be odd except 1\n",
    "med = cv2.medianBlur(img,5)\n",
    "cv2.imshow('median blur',med)\n",
    "\n",
    "# filter 5\n",
    "# bilateral filter\n",
    "# it is highly effective at noise removal while preserving edges\n",
    "# it is slow as compare with other filters\n",
    "# argument(img,neighbour_pixel_diameter,sigma_color,sigma_space)\n",
    "bi_f = cv2.bilateralFilter(img,9,75,75)\n",
    "cv2.imshow('bi_f',bi_f)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image gradient\n",
    "It is directional change in the color or intensity in an image. It is most important part to find information about image. Like finding edges within the images. There are various methods to find image gradient.All load images to grayscale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Data/building.jpg',0)\n",
    "img = cv2.resize(img,(600,500))\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "# Laplacian derivative\n",
    "# (img,data_type for -ve val,ksize)\n",
    "lap = cv2.Laplacian(img,cv2.CV_64F,ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "cv2.imshow('lap',lap)\n",
    "\n",
    "# Soble operation - \n",
    "# is just a Gaussian smoothing plus differentiation operation,\n",
    "# so it is more resistant to noise\n",
    "# this is use for x and y both\n",
    "# (img,type for -val,x=1,y=0,ksize)\n",
    "# Sobel X focus on vertical lines\n",
    "# Sobel Y focus on horizontal lines\n",
    "sobelX = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)  # x-direction\n",
    "sobelY = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)  # y-direction\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "cv2.imshow('sobelX',sobelX)\n",
    "cv2.imshow('sobelY',sobelY)\n",
    "\n",
    "sobelCombine = cv2.bitwise_or(sobelX,sobelY)\n",
    "cv2.imshow('sobelCombine',sobelCombine)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canny edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Data/building.jpg',0)\n",
    "img = cv2.resize(img,(600,500))\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('Canny')\n",
    "cv2.createTrackbar(\"threshold\",\"Canny\",0,255,nothing)\n",
    "\n",
    "while True:\n",
    "    a = cv2.getTrackbarPos('threshold','Canny')\n",
    "    res = cv2.Canny(img,a,255)\n",
    "    cv2.imshow('Canny',res)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Pyramid\n",
    "We use it bcs sometimes we on same image but different resolutions and it vary image to image so in that case we create a set of images with different resolutions which is called a pyramid. it can also be used in blending images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Data/building.jpg',0)\n",
    "img = cv2.resize(img,(600,500))\n",
    "cv2.imshow('img',img)\n",
    "\n",
    "pd1 = cv2.pyrDown(img)  # x/2,y/2\n",
    "pu1 = cv2.pyrUp(img)  # x*2,y*2\n",
    "cv2.imshow('pd1',pd1)\n",
    "cv2.imshow('pu1',pu1)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contours\n",
    "These are curve joining all the countinous pointa having same color or intensity.FindCountour function manipulate original image so copy it before proceeding. it is like finding white object from black background.so you must turn image in white and background in black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Data/logo.jpg')\n",
    "img1 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret,thresh = cv2.threshold(img1,70,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# findContour(img,contour_retrival_mode,method)\n",
    "cnts,hier = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# here cnts is a list of contours and each contour is an array with x,y\n",
    "# hier variable called hierarchy and it contain image information\n",
    "\n",
    "# drawContour(img,cnts,id of contour,color,thickness)\n",
    "img = cv2.drawContours(img,cnts,-1,(176,10,15),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('b/w',img1)\n",
    "cv2.imshow('thresh',thresh)\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment in contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding center "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m00': 9217.5, 'm10': 3403082.5, 'm01': 4681369.5, 'm20': 1259863001.9166665, 'm11': 1728354771.875, 'm02': 2392045141.9166665, 'm30': 467687576127.35004, 'm21': 639823597838.9166, 'm12': 883141301256.1167, 'm03': 1229710560698.25, 'mu20': 3451773.0795361996, 'mu11': 2548.226098537445, 'mu02': 14478513.706170559, 'mu30': -90956.12762451172, 'mu21': -35536958.84927416, 'mu12': 447440.8199863434, 'mu03': 135761139.7307129, 'nu20': 0.04062711138489369, 'nu11': 2.9992430890933408e-05, 'nu02': 0.17041102513822776, 'nu30': -1.1150622076027715e-05, 'nu21': -0.00435659705628032, 'nu12': 5.485329702746838e-05, 'nu03': 0.016643421408587006}\n",
      "{'m00': 12847.0, 'm10': 2868920.833333333, 'm01': 6550380.333333333, 'm20': 646016729.0, 'm11': 1462791759.4166665, 'm02': 3372663373.1666665, 'm30': 146652244442.35, 'm21': 329386608118.95, 'm12': 753161219371.1167, 'm03': 1753072509060.1, 'mu20': 5345229.978125215, 'mu11': -2870.034329175949, 'mu02': 32779936.463926315, 'mu30': 34915.1174621582, 'mu21': -704782.3787069321, 'mu12': -344843.50710392, 'mu03': 4093645.8376464844, 'nu20': 0.032386420261621536, 'nu11': -1.738936179179603e-05, 'nu02': 0.19861162247734082, 'nu30': 1.8664192159310321e-06, 'nu21': -3.7674780160596084e-05, 'nu12': -1.843392189201077e-05, 'nu03': 0.00021882954462004568}\n",
      "{'m00': 7906.0, 'm10': 668692.8333333333, 'm01': 4064484.833333333, 'm20': 58855027.5, 'm11': 343774374.5, 'm02': 2103722679.8333333, 'm30': 5366498721.35, 'm21': 30256393492.6, 'm12': 177931692574.36667, 'm03': 1096098334094.55, 'mu20': 2296704.030311033, 'mu11': -1476.6563403606415, 'mu02': 14165766.046754599, 'mu30': 3129.951089859009, 'mu21': -802533.2211520672, 'mu12': -545678.9529976845, 'mu03': 6504064.053955078, 'nu20': 0.036744421348630256, 'nu11': -2.3624673463036385e-05, 'nu02': 0.22663472065992776, 'nu30': 5.631777988851962e-07, 'nu21': -0.0001444012638041021, 'nu12': -9.818500763251786e-05, 'nu03': 0.0011702880883930195}\n",
      "{'m00': 19623.5, 'm10': 7231228.666666666, 'm01': 3463586.833333333, 'm20': 2690243897.75, 'm11': 1276323832.2083333, 'm02': 651632194.5833333, 'm30': 1010179107883.3, 'm21': 474831715547.89996, 'm12': 240124447796.26666, 'm03': 129241222447.45001, 'mu20': 25547588.24243164, 'mu11': -2429.60475897789, 'mu02': 40302220.21382606, 'mu30': 1268.241455078125, 'mu21': 100155.78947544098, 'mu12': -126071.78963851929, 'mu03': -1998.156234741211, 'nu20': 0.06634328449260254, 'nu11': -6.309321968080584e-06, 'nu02': 0.10465886783350187, 'nu30': 2.3510440739717448e-08, 'nu21': 1.8566707023915403e-06, 'nu12': -2.337097030993949e-06, 'nu03': -3.704147467935143e-08}\n",
      "{'m00': 16000.0, 'm10': 8192000.0, 'm01': 2480000.0, 'm20': 4202837333.333333, 'm11': 1269760000.0, 'm02': 437733333.3333333, 'm30': 2160590848000.0, 'm21': 651439786666.6666, 'm12': 224119466666.66666, 'm03': 84382000000.0, 'mu20': 8533333.333333015, 'mu11': 0.0, 'mu02': 53333333.33333331, 'mu30': 0.00048828125, 'mu21': 8.58306884765625e-06, 'mu12': 0.0, 'mu03': 0.0, 'nu20': 0.03333333333333209, 'nu11': 0.0, 'nu02': 0.20833333333333326, 'nu30': 1.5078914929239174e-14, 'nu21': 2.6505905149053235e-16, 'nu12': 0.0, 'nu03': 0.0}\n",
      "{'m00': 9472.0, 'm10': 2114506.0, 'm01': 1765953.5, 'm20': 475386208.6666666, 'm11': 394227356.9166666, 'm02': 351514675.5, 'm30': 107619312726.0, 'm21': 88722661191.58333, 'm12': 78470953374.91667, 'm03': 73228333474.75, 'mu20': 3349086.19664973, 'mu11': 237.88467758893967, 'mu02': 22271457.155167878, 'mu30': -19649.16729736328, 'mu21': 91860403.59911966, 'mu12': -407543.5124902725, 'mu03': -612385161.982132, 'nu20': 0.03732870695895445, 'nu11': 2.651447857217277e-06, 'nu02': 0.24823627965318704, 'nu30': -2.250297444039191e-06, 'nu21': 0.010520203136305237, 'nu12': -4.667343458441005e-05, 'nu03': -0.07013268012435507}\n",
      "{'m00': 13998.5, 'm10': 1177509.8333333333, 'm01': 2098096.6666666665, 'm20': 105324723.08333333, 'm11': 176480864.125, 'm02': 353212881.25, 'm30': 9915201191.95, 'm21': 15785359196.433332, 'm12': 29711515998.399998, 'm03': 64555115765.3, 'mu20': 6276295.923516631, 'mu11': -4434.748728513718, 'mu02': 38749930.02824217, 'mu30': -268141.0097293854, 'mu21': 24589.278354644775, 'mu12': 1687669.0201134682, 'mu03': -155644.20794677734, 'nu20': 0.032028780919645394, 'nu11': -2.2631118288580717e-05, 'nu02': 0.19774609652738567, 'nu30': -1.1565368803426312e-05, 'nu21': 1.0605765715157934e-06, 'nu12': 7.279197857660017e-05, 'nu03': -6.713194184053923e-06}\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Data/shapes.png')\n",
    "img = cv2.resize(img,(600,700))\n",
    "img1 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret,thresh = cv2.threshold(img1,200,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cnts,hier = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img = cv2.drawContours(img,cnts,-1,(10,20,100),2)\n",
    "\n",
    "for c in cnts:\n",
    "    M  = cv2.moments(c)\n",
    "    print(M)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "    cv2.drawContours(img,[c],-1,(0,255,0),2)\n",
    "    cv2.circle(img,(cx,cy),7,(255,255,255),-1)\n",
    "    cv2.putText(img,\"center\",(cx-20,cy-20),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,255,255),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('b/w',img1)\n",
    "cv2.imshow('thresh',thresh)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contour area , approximation and Convex hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'m00': 9217.5, 'm10': 3403082.5, 'm01': 4681369.5, 'm20': 1259863001.9166665, 'm11': 1728354771.875, 'm02': 2392045141.9166665, 'm30': 467687576127.35004, 'm21': 639823597838.9166, 'm12': 883141301256.1167, 'm03': 1229710560698.25, 'mu20': 3451773.0795361996, 'mu11': 2548.226098537445, 'mu02': 14478513.706170559, 'mu30': -90956.12762451172, 'mu21': -35536958.84927416, 'mu12': 447440.8199863434, 'mu03': 135761139.7307129, 'nu20': 0.04062711138489369, 'nu11': 2.9992430890933408e-05, 'nu02': 0.17041102513822776, 'nu30': -1.1150622076027715e-05, 'nu21': -0.00435659705628032, 'nu12': 5.485329702746838e-05, 'nu03': 0.016643421408587006}\n",
      "9217.5\n",
      "{'m00': 12847.0, 'm10': 2868920.833333333, 'm01': 6550380.333333333, 'm20': 646016729.0, 'm11': 1462791759.4166665, 'm02': 3372663373.1666665, 'm30': 146652244442.35, 'm21': 329386608118.95, 'm12': 753161219371.1167, 'm03': 1753072509060.1, 'mu20': 5345229.978125215, 'mu11': -2870.034329175949, 'mu02': 32779936.463926315, 'mu30': 34915.1174621582, 'mu21': -704782.3787069321, 'mu12': -344843.50710392, 'mu03': 4093645.8376464844, 'nu20': 0.032386420261621536, 'nu11': -1.738936179179603e-05, 'nu02': 0.19861162247734082, 'nu30': 1.8664192159310321e-06, 'nu21': -3.7674780160596084e-05, 'nu12': -1.843392189201077e-05, 'nu03': 0.00021882954462004568}\n",
      "12847.0\n",
      "{'m00': 7906.0, 'm10': 668692.8333333333, 'm01': 4064484.833333333, 'm20': 58855027.5, 'm11': 343774374.5, 'm02': 2103722679.8333333, 'm30': 5366498721.35, 'm21': 30256393492.6, 'm12': 177931692574.36667, 'm03': 1096098334094.55, 'mu20': 2296704.030311033, 'mu11': -1476.6563403606415, 'mu02': 14165766.046754599, 'mu30': 3129.951089859009, 'mu21': -802533.2211520672, 'mu12': -545678.9529976845, 'mu03': 6504064.053955078, 'nu20': 0.036744421348630256, 'nu11': -2.3624673463036385e-05, 'nu02': 0.22663472065992776, 'nu30': 5.631777988851962e-07, 'nu21': -0.0001444012638041021, 'nu12': -9.818500763251786e-05, 'nu03': 0.0011702880883930195}\n",
      "7906.0\n",
      "{'m00': 19623.5, 'm10': 7231228.666666666, 'm01': 3463586.833333333, 'm20': 2690243897.75, 'm11': 1276323832.2083333, 'm02': 651632194.5833333, 'm30': 1010179107883.3, 'm21': 474831715547.89996, 'm12': 240124447796.26666, 'm03': 129241222447.45001, 'mu20': 25547588.24243164, 'mu11': -2429.60475897789, 'mu02': 40302220.21382606, 'mu30': 1268.241455078125, 'mu21': 100155.78947544098, 'mu12': -126071.78963851929, 'mu03': -1998.156234741211, 'nu20': 0.06634328449260254, 'nu11': -6.309321968080584e-06, 'nu02': 0.10465886783350187, 'nu30': 2.3510440739717448e-08, 'nu21': 1.8566707023915403e-06, 'nu12': -2.337097030993949e-06, 'nu03': -3.704147467935143e-08}\n",
      "19623.5\n",
      "{'m00': 16000.0, 'm10': 8192000.0, 'm01': 2480000.0, 'm20': 4202837333.333333, 'm11': 1269760000.0, 'm02': 437733333.3333333, 'm30': 2160590848000.0, 'm21': 651439786666.6666, 'm12': 224119466666.66666, 'm03': 84382000000.0, 'mu20': 8533333.333333015, 'mu11': 0.0, 'mu02': 53333333.33333331, 'mu30': 0.00048828125, 'mu21': 8.58306884765625e-06, 'mu12': 0.0, 'mu03': 0.0, 'nu20': 0.03333333333333209, 'nu11': 0.0, 'nu02': 0.20833333333333326, 'nu30': 1.5078914929239174e-14, 'nu21': 2.6505905149053235e-16, 'nu12': 0.0, 'nu03': 0.0}\n",
      "16000.0\n",
      "{'m00': 9472.0, 'm10': 2114506.0, 'm01': 1765953.5, 'm20': 475386208.6666666, 'm11': 394227356.9166666, 'm02': 351514675.5, 'm30': 107619312726.0, 'm21': 88722661191.58333, 'm12': 78470953374.91667, 'm03': 73228333474.75, 'mu20': 3349086.19664973, 'mu11': 237.88467758893967, 'mu02': 22271457.155167878, 'mu30': -19649.16729736328, 'mu21': 91860403.59911966, 'mu12': -407543.5124902725, 'mu03': -612385161.982132, 'nu20': 0.03732870695895445, 'nu11': 2.651447857217277e-06, 'nu02': 0.24823627965318704, 'nu30': -2.250297444039191e-06, 'nu21': 0.010520203136305237, 'nu12': -4.667343458441005e-05, 'nu03': -0.07013268012435507}\n",
      "9472.0\n",
      "{'m00': 13998.5, 'm10': 1177509.8333333333, 'm01': 2098096.6666666665, 'm20': 105324723.08333333, 'm11': 176480864.125, 'm02': 353212881.25, 'm30': 9915201191.95, 'm21': 15785359196.433332, 'm12': 29711515998.399998, 'm03': 64555115765.3, 'mu20': 6276295.923516631, 'mu11': -4434.748728513718, 'mu02': 38749930.02824217, 'mu30': -268141.0097293854, 'mu21': 24589.278354644775, 'mu12': 1687669.0201134682, 'mu03': -155644.20794677734, 'nu20': 0.032028780919645394, 'nu11': -2.2631118288580717e-05, 'nu02': 0.19774609652738567, 'nu30': -1.1565368803426312e-05, 'nu21': 1.0605765715157934e-06, 'nu12': 7.279197857660017e-05, 'nu03': -6.713194184053923e-06}\n",
      "13998.5\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('Data/shapes.png')\n",
    "img = cv2.resize(img,(600,700))\n",
    "img1 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret,thresh = cv2.threshold(img1,200,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cnts,hier = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "img = cv2.drawContours(img,cnts,-1,(10,20,100),2)\n",
    "for c in cnts:\n",
    "    M  = cv2.moments(c)\n",
    "    print(M)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "\n",
    "    # find area of contour\n",
    "    area = cv2.contourArea(c)\n",
    "    print(area)\n",
    "\n",
    "    # contour approx - it is used to approx shaoe with less number of vertices\n",
    "    epsilon = 0.01 * cv2.arcLength(c,True)\n",
    "    data = cv2.approxPolyDP(c,epsilon,True)\n",
    "\n",
    "    # contout hell is used to provide proper contours convexity\n",
    "    hull = cv2.convexHull(data)\n",
    "    x,y,w,h = cv2.boundingRect(hull)\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(125,10,20),5)\n",
    "    \n",
    "    cv2.drawContours(img,[c],-1,(0,255,0),2)\n",
    "    cv2.circle(img,(cx,cy),7,(255,255,255),-1)\n",
    "    cv2.putText(img,\"center\",(cx-20,cy-20),cv2.FONT_HERSHEY_COMPLEX,0.5,(255,255,255),2)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('b/w',img1)\n",
    "cv2.imshow('thresh',thresh)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand detection using contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('Data/hand.jpg')\n",
    "img = cv2.resize(img,(600,700))\n",
    "img1 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "blur = cv2.medianBlur(img1,9)\n",
    "ret,thresh = cv2.threshold(blur,240,255,cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cnts,hier = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cv2.drawContours(img,cnts,-1,(50,50,150),2)\n",
    "\n",
    "for c in cnts:\n",
    "    epsilon = 0.0001*cv2.arcLength(c,True)\n",
    "    data = cv2.approxPolyDP(c,epsilon,True)\n",
    "\n",
    "    hull = cv2.convexHull(data)\n",
    "    \n",
    "    cv2.drawContours(img,[c],-1,(50,50,150),2)\n",
    "    cv2.drawContours(img,[hull],-1,(0,255,0),2)\n",
    "\n",
    "# find convexity defect\n",
    "hull2 = cv2.convexHull(cnts[0],returnPoints=False)\n",
    "# defect returns an array which contain value [start_point,end_point,fathest_point,approx_point]\n",
    "defect = cv2.convexityDefects(cnts[0],hull2)\n",
    "\n",
    "# Extreme points \n",
    "# It means topmost, bottommost,rightmost,leftmost points of object\n",
    "\n",
    "c_max = max(cnts,key=cv2.contourArea)\n",
    "\n",
    "# determine the most extreme points along the contour\n",
    "extLeft = tuple(c_max[c_max[:,:,0].argmin()][0])\n",
    "extRight = tuple(c_max[c_max[:,:,0].argmax()][0])\n",
    "extTop = tuple(c_max[c_max[:,:,1].argmin()][0])\n",
    "extBot = tuple(c_max[c_max[:,:,1].argmax()][0])\n",
    "\n",
    "# draw the outline of the object , then draw each of the extreme points ,\n",
    "# where the leftmost is red,rightmost is green,topmost is blue,bottommost is teal\n",
    "\n",
    "cv2.circle(img,extLeft,8,(255,0,255),-1)\n",
    "cv2.circle(img,extRight,8,(0,125,255),-1)\n",
    "cv2.circle(img,extTop,8,(255,10,0),-1)\n",
    "cv2.circle(img,extBot,8,(19,152,152),-1)\n",
    "\n",
    "for i in range(defect.shape[0]):\n",
    "    s,e,f,d = defect[i,0]\n",
    "    start = tuple(c[s][0])\n",
    "    end = tuple(c[e][0])\n",
    "    far = tuple(c[f][0])\n",
    "    cv2.circle(img,far,5,[0,0,255],-1)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.imshow('gray',img1)\n",
    "cv2.imshow('thresh',thresh)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contour detection using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow('Color Adjustments',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Color Adjustments',(300,300))\n",
    "cv2.createTrackbar('Thresh','Color Adjustments',0,255,nothing)\n",
    "\n",
    "cv2.createTrackbar(\"Lower_H\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_S\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Lower_V\", \"Color Adjustments\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_H\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_S\", \"Color Adjustments\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"Upper_V\", \"Color Adjustments\", 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    _,frame = cap.read()\n",
    "    frame = cv2.resize(frame,(400,400))\n",
    "    hsv = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    l_h = cv2.getTrackbarPos(\"Lower_H\", \"Color Adjustments\")\n",
    "    l_s = cv2.getTrackbarPos(\"Lower_S\", \"Color Adjustments\")\n",
    "    l_v = cv2.getTrackbarPos(\"Lower_V\", \"Color Adjustments\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"Upper_H\", \"Color Adjustments\")\n",
    "    u_s = cv2.getTrackbarPos(\"Upper_S\", \"Color Adjustments\")\n",
    "    u_v = cv2.getTrackbarPos(\"Upper_V\", \"Color Adjustments\")\n",
    "    \n",
    "    lower_bound = np.array([l_h, l_s, l_v])\n",
    "    upper_bound = np.array([u_h, u_s, u_v])\n",
    "\n",
    "    mask = cv2.inRange(hsv,lower_bound,upper_bound)\n",
    "    filter = cv2.bitwise_and(frame,frame,mask=mask)\n",
    "\n",
    "    mask1 = cv2.bitwise_not(mask)\n",
    "    m_g = cv2.getTrackbarPos(\"Thresh\", \"Color Adjustments\")\n",
    "    ret,thresh = cv2.threshold(mask1,m_g,255,cv2.THRESH_BINARY)\n",
    "    dilata = cv2.dilate(thresh,(1,1),iterations=6)\n",
    "\n",
    "    cnts,hier = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for c in cnts:\n",
    "        epsilon = 0.0001*cv2.arcLength(c,True)\n",
    "        data = cv2.approxPolyDP(c,epsilon,True)\n",
    "\n",
    "        hull = cv2.convexHull(data)\n",
    "        cv2.drawContours(frame,[c],-1,(50,50,150),2)\n",
    "        cv2.drawContours(frame,[hull],-1,(0,255,0),2)\n",
    "\n",
    "        hull = cv2.convexHull(data,returnPoints=False)\n",
    "        defect = cv2.convexityDefects(data[0],hull)\n",
    "\n",
    "    cv2.imshow(\"Thresh\",thresh)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('filter',filter)\n",
    "    cv2.imshow('Result',frame)\n",
    "\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
